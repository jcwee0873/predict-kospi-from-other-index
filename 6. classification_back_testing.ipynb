{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7fa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822b5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_csv('./data/nasdaq.csv', index_col=0, parse_dates=True)\n",
    "snp = pd.read_csv('./data/snp500.csv', index_col=0, parse_dates=True)\n",
    "ftse = pd.read_csv('./data/ftse.csv', index_col=0, parse_dates=True)\n",
    "dax = pd.read_csv('./data/dax.csv', index_col=0, parse_dates=True)\n",
    "nikkei = pd.read_csv('./data/nikkei.csv', index_col=1, parse_dates=True)\n",
    "hangseng = pd.read_csv('./data/hang.csv', index_col=0, parse_dates=True)\n",
    "sanghai = pd.read_csv('./data/sanghai.csv', index_col=0, parse_dates=True)\n",
    "kospi = pd.read_csv('./data/kospi.csv', index_col=0, parse_dates=True)\n",
    "kosdaq = pd.read_csv('./data/kosdaq.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccc39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.sort_index(inplace=True)\n",
    "snp.sort_index(inplace=True)\n",
    "ftse.sort_index(inplace=True)\n",
    "dax.sort_index(inplace=True)\n",
    "nikkei.sort_index(inplace=True)\n",
    "hangseng.sort_index(inplace=True)\n",
    "sanghai.sort_index(inplace=True)\n",
    "kospi.sort_index(inplace=True)\n",
    "kosdaq.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852f9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq['Close'] = nasdaq.Close.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "dax['Close'] = dax.Close.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "nikkei['Close'] = nikkei['종가'].apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "hangseng['Close'] = hangseng.Close.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "\n",
    "nasdaq['Open'] = nasdaq.Open.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "dax['Open'] = dax.Open.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "nikkei['Open'] = nikkei['오픈'].apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "hangseng['Open'] = hangseng.Open.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "\n",
    "nasdaq['High'] = nasdaq.High.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "dax['High'] = dax.High.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "nikkei['High'] = nikkei['고가'].apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "hangseng['High'] = hangseng.High.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "\n",
    "nasdaq['Low'] = nasdaq.Low.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "dax['Low'] = dax.Low.apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "nikkei['Low'] = nikkei['저가'].apply(lambda x : pd.to_numeric(x.replace(',', '')))\n",
    "hangseng['Low'] = hangseng.Low.apply(lambda x : pd.to_numeric(x.replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7210525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [nasdaq, snp, ftse, dax, nikkei, hangseng, sanghai, kospi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa56045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = []\n",
    "df2 = []\n",
    "df3 = []\n",
    "df4 = []\n",
    "df5 = []\n",
    "df6 = []\n",
    "df7 = []\n",
    "df8 = []\n",
    "df9 = []\n",
    "for df in df_list:\n",
    "    df1.append((df.Close - df.Close.shift(1)) / df.Close.shift(1))\n",
    "    df2.append((df.Close - df.Open) / df.Open)\n",
    "    df3.append((df.High - df.Low) / df.Low)\n",
    "    df4.append((df.High - df.Close) / df.Close)\n",
    "    df5.append((df.Low - df.Close) / df.Close)\n",
    "    df6.append((df.Open - df.Open.shift(1)) / df.Open.shift(1))\n",
    "    df7.append((df.Open - df.Close.shift(1)) / df.Close.shift(1))\n",
    "    df8.append((df.High - df.High.shift(1)) / df.High.shift(1))\n",
    "    df9.append((df.Low - df.Low.shift(1)) / df.Low.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eacaef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat(df1, axis=1)\n",
    "df2 = pd.concat(df2, axis=1)\n",
    "df3 = pd.concat(df3, axis=1)\n",
    "df4 = pd.concat(df4, axis=1)\n",
    "df5 = pd.concat(df5, axis=1)\n",
    "df6 = pd.concat(df6, axis=1)\n",
    "df7 = pd.concat(df7, axis=1)\n",
    "df8 = pd.concat(df8, axis=1)\n",
    "df9 = pd.concat(df9, axis=1)\n",
    "\n",
    "tail = '_1'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df1.columns = col_names\n",
    "\n",
    "tail = '_2'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df2.columns = col_names\n",
    "\n",
    "tail = '_3'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df3.columns = col_names\n",
    "\n",
    "tail = '_4'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df4.columns = col_names\n",
    "\n",
    "tail = '_5'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df5.columns = col_names\n",
    "\n",
    "tail = '_6'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df6.columns = col_names\n",
    "\n",
    "tail = '_7'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df7.columns = col_names\n",
    "\n",
    "tail = '_8'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df8.columns = col_names\n",
    "\n",
    "tail = '_9'\n",
    "col_names = [f'NASDAQ{tail}', f'S&P500{tail}', f'FTSE{tail}', f'DAX{tail}',\n",
    "             f'NIKKEI{tail}', f'HANGSENG{tail}', f'SANGHAI{tail}', f'KOSPI{tail}']\n",
    "df9.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f29f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b6caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(pd.DataFrame(pd.date_range('2001-01-01', '2021-11-11')).set_index(0),final_df,how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baacc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna(0, inplace=True)\n",
    "final_df = final_df.loc['2001-01-03' : '2021-11-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4848617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1505d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (kospi.Close - kospi.Open) / kospi.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e4f42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.name = 'y'\n",
    "y = pd.merge(pd.DataFrame(pd.date_range('2001-01-01', '2021-11-11')).set_index(0),y,how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dcfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y.loc['2001-01-03' : '2021-11-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5894fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/f7hm_xxs1bb1k3q0vxk7zc_w0000gn/T/ipykernel_7022/3400580676.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_df['b'] = y_df.y.apply(bull_or_bear)\n"
     ]
    }
   ],
   "source": [
    "y_df['b'] = y_df.y.apply(lambda x : x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5db852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>0.016948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>0.011767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>0.038085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>-0.001740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>0.001457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>-0.005866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-11</th>\n",
       "      <td>0.004640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7618 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y  b\n",
       "2001-01-03  0.016948  1\n",
       "2001-01-04  0.011767  1\n",
       "2001-01-05  0.038085  1\n",
       "2001-01-06       NaN  0\n",
       "2001-01-07       NaN  0\n",
       "...              ... ..\n",
       "2021-11-07       NaN  0\n",
       "2021-11-08 -0.001740  0\n",
       "2021-11-09  0.001457  1\n",
       "2021-11-10 -0.005866  0\n",
       "2021-11-11  0.004640  1\n",
       "\n",
       "[7618 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1f01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_index = y_df[y_df.y.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae107cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77c64c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N번째 휴일의 시작 날짜, 처음 값을 0번째 인덱스 값으로 지정.\n",
    "start_day = holiday_index[0]\n",
    "\n",
    "# N번째 휴일의 종료 날짜\n",
    "end_day = holiday_index[0]\n",
    "\n",
    "# 휴일기간을 담기위한 목록\n",
    "holiday_list = []\n",
    "\n",
    "for i in range(1, len(holiday_index)) :\n",
    "    \n",
    "    # N번째 휴일 날짜를 N-1번째 휴일 날짜와 비교해서, 날짜의 차이가 1일이면\n",
    "    if (holiday_index[i] - holiday_index[i-1]) == timedelta(days=1) :\n",
    "        \n",
    "        # 연속된 휴일로 보고 휴일 종료 날짜를 +1일\n",
    "        end_day = holiday_index[i]\n",
    "        \n",
    "    # N번째 휴일 날짜와 N-1번째 휴일 날짜를 비교해서, 날짜의 차이가 1일이 아니면 -> 새로운 휴일의 시작으로 보고 시작과 끝을 바꿔줌.\n",
    "    else :\n",
    "        \n",
    "        # 새로운 휴일을 시작하기 전에 정해진(이전 휴일기간)의 시작과 끝 날짜를 리스트에 담아줌.\n",
    "        holiday_list.append((start_day, end_day))\n",
    "        \n",
    "        # 새로운 휴일 시작 날짜를 새로 지정\n",
    "        start_day = holiday_index[i]\n",
    "        \n",
    "        # 새로운 휴일 종료 날짜도 새로 지정\n",
    "        end_day = holiday_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ab67997",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = timedelta(days=1)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "temp = None\n",
    "\n",
    "for idx in range(len(holiday_list)) :\n",
    "    \n",
    "    #휴일 시작일\n",
    "    holiday_start = holiday_list[idx][0]\n",
    "    \n",
    "    #휴일 종료일\n",
    "    holiday_end = holiday_list[idx][1]\n",
    "    \n",
    "    # 타겟 날짜(휴일 다음날의 날짜)\n",
    "    target_day = holiday_end + one_day\n",
    "    \n",
    "    # 휴일기간 및 D+1일 지수 변동 데이터\n",
    "    n_holiday = final_df.loc[holiday_start - one_day : holiday_end]\n",
    "    \n",
    "#     if len(n_holiday) > 3:\n",
    "#         temp = n_holiday\n",
    "#         break\n",
    "    \n",
    "    # 휴일 기간 동안 지수들의 누적 변동률\n",
    "    n_holiday_change = (n_holiday + 1).cumprod() - 1\n",
    "\n",
    "    # KOSPI, KOSDAQ을 제외한 지수들의 누적수익률 데이터\n",
    "    X_data = n_holiday_change.loc[holiday_end]\n",
    "\n",
    "    # D+1일 KOSPI의 실제 수익률 y\n",
    "    y_data = y_df.loc[target_day]['b']\n",
    "\n",
    "    X.append(X_data.values)\n",
    "    y.append(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f185e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1fce3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "462478b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f40a7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "098bce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "lgbm = lightgbm.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff772b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8f2751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a181e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------log--------------------\n",
      "train: 0.5353535353535354\n",
      "test: 0.5252525252525253\n",
      "accuracy: 0.5252525252525253\n",
      "recall 0.5294117647058824\n",
      "precision 0.06338028169014084\n",
      "f1 0.11320754716981132\n",
      "\n",
      "\n",
      "--------------------rfc--------------------\n",
      "train: 1.0\n",
      "test: 0.5353535353535354\n",
      "accuracy: 0.5353535353535354\n",
      "recall 0.5172413793103449\n",
      "precision 0.4225352112676056\n",
      "f1 0.46511627906976744\n",
      "\n",
      "\n",
      "--------------------gbc--------------------\n",
      "train: 0.9483726150392817\n",
      "test: 0.5589225589225589\n",
      "accuracy: 0.5589225589225589\n",
      "recall 0.5419847328244275\n",
      "precision 0.5\n",
      "f1 0.5201465201465201\n",
      "\n",
      "\n",
      "--------------------lgbm--------------------\n",
      "train: 1.0\n",
      "test: 0.5555555555555556\n",
      "accuracy: 0.5555555555555556\n",
      "recall 0.5367647058823529\n",
      "precision 0.5140845070422535\n",
      "f1 0.525179856115108\n"
     ]
    }
   ],
   "source": [
    "print('--------------------log--------------------')\n",
    "print('train:', log.score(X_train, y_train))\n",
    "print('test:', log.score(X_test, y_test))\n",
    "print('accuracy:', accuracy_score(log.predict(X_test), y_test))\n",
    "print('recall', recall_score(log.predict(X_test), y_test))\n",
    "print('precision', precision_score(log.predict(X_test), y_test))\n",
    "print('f1', f1_score(log.predict(X_test), y_test))\n",
    "\n",
    "\n",
    "print('\\n\\n--------------------rfc--------------------')\n",
    "print('train:', rfc.score(X_train, y_train))\n",
    "print('test:', rfc.score(X_test, y_test))\n",
    "print('accuracy:', accuracy_score(rfc.predict(X_test), y_test))\n",
    "print('recall', recall_score(rfc.predict(X_test), y_test))\n",
    "print('precision', precision_score(rfc.predict(X_test), y_test))\n",
    "print('f1', f1_score(rfc.predict(X_test), y_test))\n",
    "\n",
    "print('\\n\\n--------------------gbc--------------------')\n",
    "print('train:', gbc.score(X_train, y_train))\n",
    "print('test:', gbc.score(X_test, y_test))\n",
    "print('accuracy:', accuracy_score(gbc.predict(X_test), y_test))\n",
    "print('recall', recall_score(gbc.predict(X_test), y_test))\n",
    "print('precision', precision_score(gbc.predict(X_test), y_test))\n",
    "print('f1', f1_score(gbc.predict(X_test), y_test))\n",
    "\n",
    "print('\\n\\n--------------------lgbm--------------------')\n",
    "print('train:', lgbm.score(X_train, y_train))\n",
    "print('test:', lgbm.score(X_test, y_test))\n",
    "print('accuracy:', accuracy_score(lgbm.predict(X_test), y_test))\n",
    "print('recall', recall_score(lgbm.predict(X_test), y_test))\n",
    "print('precision', precision_score(lgbm.predict(X_test), y_test))\n",
    "print('f1', f1_score(lgbm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d678ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1e51b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "957b42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f45c3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e01021ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                2336      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,402\n",
      "Trainable params: 2,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation = tf.nn.leaky_relu\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_dim = 72, activation = activation))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "36a8cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "638d6450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 47/581 [=>............................] - ETA: 1s - loss: 0.6918 - accuracy: 0.5532  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 10:09:12.542310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566/581 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 10:09:14.428587: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5009 - val_loss: 0.6933 - val_accuracy: 0.4920\n",
      "Epoch 2/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5284 - val_loss: 0.6899 - val_accuracy: 0.5280\n",
      "Epoch 3/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6872 - accuracy: 0.5577 - val_loss: 0.6915 - val_accuracy: 0.5240\n",
      "Epoch 4/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6831 - accuracy: 0.5422 - val_loss: 0.6869 - val_accuracy: 0.5360\n",
      "Epoch 5/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6781 - accuracy: 0.5714 - val_loss: 0.6992 - val_accuracy: 0.5120\n",
      "Epoch 6/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6756 - accuracy: 0.5680 - val_loss: 0.6898 - val_accuracy: 0.5360\n",
      "Epoch 7/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6695 - accuracy: 0.5886 - val_loss: 0.6883 - val_accuracy: 0.5400\n",
      "Epoch 8/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6698 - accuracy: 0.6024 - val_loss: 0.7032 - val_accuracy: 0.4840\n",
      "Epoch 9/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6679 - accuracy: 0.5835 - val_loss: 0.6911 - val_accuracy: 0.5400\n",
      "Epoch 10/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6676 - accuracy: 0.5869 - val_loss: 0.6939 - val_accuracy: 0.5280\n",
      "Epoch 11/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6631 - accuracy: 0.5835 - val_loss: 0.7004 - val_accuracy: 0.5240\n",
      "Epoch 12/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6568 - accuracy: 0.5938 - val_loss: 0.6945 - val_accuracy: 0.5120\n",
      "Epoch 13/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6615 - accuracy: 0.5869 - val_loss: 0.7048 - val_accuracy: 0.5200\n",
      "Epoch 14/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6579 - accuracy: 0.6093 - val_loss: 0.7011 - val_accuracy: 0.5240\n",
      "Epoch 15/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6559 - accuracy: 0.6007 - val_loss: 0.7066 - val_accuracy: 0.5160\n",
      "Epoch 16/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.6076 - val_loss: 0.7028 - val_accuracy: 0.5160\n",
      "Epoch 17/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6558 - accuracy: 0.6024 - val_loss: 0.7047 - val_accuracy: 0.5160\n",
      "Epoch 18/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6509 - accuracy: 0.6059 - val_loss: 0.7246 - val_accuracy: 0.5080\n",
      "Epoch 19/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6541 - accuracy: 0.5852 - val_loss: 0.7033 - val_accuracy: 0.5400\n",
      "Epoch 20/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6525 - accuracy: 0.6248 - val_loss: 0.7092 - val_accuracy: 0.5080\n",
      "Epoch 21/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6527 - accuracy: 0.6145 - val_loss: 0.7087 - val_accuracy: 0.5120\n",
      "Epoch 22/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6494 - accuracy: 0.6179 - val_loss: 0.7163 - val_accuracy: 0.5080\n",
      "Epoch 23/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6510 - accuracy: 0.6145 - val_loss: 0.7127 - val_accuracy: 0.5120\n",
      "Epoch 24/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6481 - accuracy: 0.6110 - val_loss: 0.7127 - val_accuracy: 0.5080\n",
      "Epoch 25/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6457 - accuracy: 0.6196 - val_loss: 0.7132 - val_accuracy: 0.5200\n",
      "Epoch 26/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6460 - accuracy: 0.6162 - val_loss: 0.7125 - val_accuracy: 0.5200\n",
      "Epoch 27/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6447 - accuracy: 0.6231 - val_loss: 0.7124 - val_accuracy: 0.5120\n",
      "Epoch 28/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6445 - accuracy: 0.6213 - val_loss: 0.7134 - val_accuracy: 0.5200\n",
      "Epoch 29/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6440 - accuracy: 0.6231 - val_loss: 0.7265 - val_accuracy: 0.5040\n",
      "Epoch 30/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6433 - accuracy: 0.6076 - val_loss: 0.7260 - val_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6392 - accuracy: 0.6231 - val_loss: 0.7301 - val_accuracy: 0.4960\n",
      "Epoch 32/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6388 - accuracy: 0.6454 - val_loss: 0.7201 - val_accuracy: 0.5160\n",
      "Epoch 33/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6373 - accuracy: 0.6420 - val_loss: 0.7200 - val_accuracy: 0.5120\n",
      "Epoch 34/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6374 - accuracy: 0.6299 - val_loss: 0.7277 - val_accuracy: 0.5000\n",
      "Epoch 35/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6358 - accuracy: 0.6334 - val_loss: 0.7224 - val_accuracy: 0.5120\n",
      "Epoch 36/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6330 - accuracy: 0.6386 - val_loss: 0.7234 - val_accuracy: 0.5120\n",
      "Epoch 37/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6360 - accuracy: 0.6265 - val_loss: 0.7309 - val_accuracy: 0.4960\n",
      "Epoch 38/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6323 - accuracy: 0.6454 - val_loss: 0.7339 - val_accuracy: 0.5080\n",
      "Epoch 39/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6306 - accuracy: 0.6420 - val_loss: 0.7371 - val_accuracy: 0.5120\n",
      "Epoch 40/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6293 - accuracy: 0.6713 - val_loss: 0.7531 - val_accuracy: 0.4920\n",
      "Epoch 41/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6271 - accuracy: 0.6420 - val_loss: 0.7428 - val_accuracy: 0.4880\n",
      "Epoch 42/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6267 - accuracy: 0.6454 - val_loss: 0.7340 - val_accuracy: 0.5240\n",
      "Epoch 43/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6224 - accuracy: 0.6386 - val_loss: 0.7346 - val_accuracy: 0.5320\n",
      "Epoch 44/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6243 - accuracy: 0.6403 - val_loss: 0.7478 - val_accuracy: 0.4880\n",
      "Epoch 45/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6245 - accuracy: 0.6627 - val_loss: 0.7400 - val_accuracy: 0.5000\n",
      "Epoch 46/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6224 - accuracy: 0.6472 - val_loss: 0.7476 - val_accuracy: 0.4840\n",
      "Epoch 47/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6246 - accuracy: 0.6523 - val_loss: 0.7434 - val_accuracy: 0.4800\n",
      "Epoch 48/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6166 - accuracy: 0.6575 - val_loss: 0.7415 - val_accuracy: 0.5160\n",
      "Epoch 49/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6204 - accuracy: 0.6489 - val_loss: 0.7430 - val_accuracy: 0.5200\n",
      "Epoch 50/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6142 - accuracy: 0.6592 - val_loss: 0.7676 - val_accuracy: 0.4760\n",
      "Epoch 51/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6198 - accuracy: 0.6730 - val_loss: 0.7473 - val_accuracy: 0.5000\n",
      "Epoch 52/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6156 - accuracy: 0.6540 - val_loss: 0.7629 - val_accuracy: 0.4800\n",
      "Epoch 53/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6137 - accuracy: 0.6764 - val_loss: 0.7526 - val_accuracy: 0.4840\n",
      "Epoch 54/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6134 - accuracy: 0.6781 - val_loss: 0.7567 - val_accuracy: 0.4800\n",
      "Epoch 55/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6100 - accuracy: 0.6764 - val_loss: 0.7782 - val_accuracy: 0.4760\n",
      "Epoch 56/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6139 - accuracy: 0.6472 - val_loss: 0.7754 - val_accuracy: 0.4880\n",
      "Epoch 57/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6110 - accuracy: 0.6695 - val_loss: 0.7582 - val_accuracy: 0.5040\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6095 - accuracy: 0.6695 - val_loss: 0.7645 - val_accuracy: 0.4800\n",
      "Epoch 59/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6078 - accuracy: 0.6695 - val_loss: 0.7613 - val_accuracy: 0.5160\n",
      "Epoch 60/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.6713 - val_loss: 0.7713 - val_accuracy: 0.4600\n",
      "Epoch 61/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6053 - accuracy: 0.6678 - val_loss: 0.7709 - val_accuracy: 0.4560\n",
      "Epoch 62/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6038 - accuracy: 0.6695 - val_loss: 0.7911 - val_accuracy: 0.4840\n",
      "Epoch 63/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6032 - accuracy: 0.6764 - val_loss: 0.7813 - val_accuracy: 0.4680\n",
      "Epoch 64/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5983 - accuracy: 0.6816 - val_loss: 0.7736 - val_accuracy: 0.5120\n",
      "Epoch 65/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.6005 - accuracy: 0.6850 - val_loss: 0.7854 - val_accuracy: 0.4640\n",
      "Epoch 66/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5987 - accuracy: 0.6713 - val_loss: 0.7766 - val_accuracy: 0.4920\n",
      "Epoch 67/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5962 - accuracy: 0.6850 - val_loss: 0.7893 - val_accuracy: 0.4720\n",
      "Epoch 68/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5952 - accuracy: 0.6799 - val_loss: 0.7799 - val_accuracy: 0.5000\n",
      "Epoch 69/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5955 - accuracy: 0.6971 - val_loss: 0.7865 - val_accuracy: 0.4920\n",
      "Epoch 70/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5945 - accuracy: 0.6988 - val_loss: 0.7851 - val_accuracy: 0.4920\n",
      "Epoch 71/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5928 - accuracy: 0.6799 - val_loss: 0.7837 - val_accuracy: 0.5000\n",
      "Epoch 72/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5922 - accuracy: 0.6936 - val_loss: 0.8066 - val_accuracy: 0.4880\n",
      "Epoch 73/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5913 - accuracy: 0.6730 - val_loss: 0.7910 - val_accuracy: 0.4760\n",
      "Epoch 74/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5881 - accuracy: 0.6954 - val_loss: 0.7918 - val_accuracy: 0.4880\n",
      "Epoch 75/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5865 - accuracy: 0.7057 - val_loss: 0.8106 - val_accuracy: 0.4920\n",
      "Epoch 76/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5885 - accuracy: 0.6919 - val_loss: 0.8120 - val_accuracy: 0.4800\n",
      "Epoch 77/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5855 - accuracy: 0.6954 - val_loss: 0.8136 - val_accuracy: 0.4960\n",
      "Epoch 78/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5859 - accuracy: 0.7040 - val_loss: 0.8042 - val_accuracy: 0.4960\n",
      "Epoch 79/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5810 - accuracy: 0.7005 - val_loss: 0.8329 - val_accuracy: 0.4600\n",
      "Epoch 80/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5828 - accuracy: 0.6902 - val_loss: 0.8064 - val_accuracy: 0.4920\n",
      "Epoch 81/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5831 - accuracy: 0.6816 - val_loss: 0.8095 - val_accuracy: 0.4640\n",
      "Epoch 82/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5811 - accuracy: 0.6971 - val_loss: 0.8034 - val_accuracy: 0.4880\n",
      "Epoch 83/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5801 - accuracy: 0.6971 - val_loss: 0.8170 - val_accuracy: 0.4560\n",
      "Epoch 84/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5790 - accuracy: 0.7057 - val_loss: 0.8403 - val_accuracy: 0.4600\n",
      "Epoch 85/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5779 - accuracy: 0.7022 - val_loss: 0.8096 - val_accuracy: 0.4840\n",
      "Epoch 86/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5745 - accuracy: 0.7057 - val_loss: 0.8124 - val_accuracy: 0.4920\n",
      "Epoch 87/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5733 - accuracy: 0.7091 - val_loss: 0.8409 - val_accuracy: 0.4720\n",
      "Epoch 88/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5752 - accuracy: 0.7040 - val_loss: 0.8292 - val_accuracy: 0.4760\n",
      "Epoch 89/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5731 - accuracy: 0.7126 - val_loss: 0.8264 - val_accuracy: 0.4720\n",
      "Epoch 90/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5703 - accuracy: 0.6936 - val_loss: 0.8178 - val_accuracy: 0.4920\n",
      "Epoch 91/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5735 - accuracy: 0.6902 - val_loss: 0.8203 - val_accuracy: 0.4880\n",
      "Epoch 92/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5697 - accuracy: 0.7057 - val_loss: 0.8266 - val_accuracy: 0.4800\n",
      "Epoch 93/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5686 - accuracy: 0.7281 - val_loss: 0.8250 - val_accuracy: 0.5080\n",
      "Epoch 94/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.7091 - val_loss: 0.8437 - val_accuracy: 0.4640\n",
      "Epoch 95/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7212 - val_loss: 0.8363 - val_accuracy: 0.4720\n",
      "Epoch 96/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.7246 - val_loss: 0.8480 - val_accuracy: 0.4840\n",
      "Epoch 97/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.7281 - val_loss: 0.8335 - val_accuracy: 0.5000\n",
      "Epoch 98/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.7126 - val_loss: 0.8575 - val_accuracy: 0.4760\n",
      "Epoch 99/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5627 - accuracy: 0.7229 - val_loss: 0.8437 - val_accuracy: 0.4920\n",
      "Epoch 100/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5624 - accuracy: 0.7281 - val_loss: 0.8444 - val_accuracy: 0.4800\n",
      "Epoch 101/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5605 - accuracy: 0.7160 - val_loss: 0.8422 - val_accuracy: 0.5160\n",
      "Epoch 102/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.7212 - val_loss: 0.8425 - val_accuracy: 0.4760\n",
      "Epoch 103/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.7246 - val_loss: 0.8453 - val_accuracy: 0.4920\n",
      "Epoch 104/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.7091 - val_loss: 0.8436 - val_accuracy: 0.4920\n",
      "Epoch 105/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5544 - accuracy: 0.7263 - val_loss: 0.8822 - val_accuracy: 0.4600\n",
      "Epoch 106/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5590 - accuracy: 0.7212 - val_loss: 0.8824 - val_accuracy: 0.4600\n",
      "Epoch 107/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5539 - accuracy: 0.7057 - val_loss: 0.8507 - val_accuracy: 0.4840\n",
      "Epoch 108/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5520 - accuracy: 0.7108 - val_loss: 0.8654 - val_accuracy: 0.4920\n",
      "Epoch 109/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5582 - accuracy: 0.7194 - val_loss: 0.8534 - val_accuracy: 0.4920\n",
      "Epoch 110/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5523 - accuracy: 0.7177 - val_loss: 0.8600 - val_accuracy: 0.4840\n",
      "Epoch 111/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5516 - accuracy: 0.7332 - val_loss: 0.8691 - val_accuracy: 0.4760\n",
      "Epoch 112/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5523 - accuracy: 0.7212 - val_loss: 0.8733 - val_accuracy: 0.4720\n",
      "Epoch 113/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5508 - accuracy: 0.7298 - val_loss: 0.8622 - val_accuracy: 0.4680\n",
      "Epoch 114/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5462 - accuracy: 0.7384 - val_loss: 0.8699 - val_accuracy: 0.4880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5471 - accuracy: 0.7298 - val_loss: 0.8707 - val_accuracy: 0.4760\n",
      "Epoch 116/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5484 - accuracy: 0.7367 - val_loss: 0.8759 - val_accuracy: 0.4760\n",
      "Epoch 117/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5453 - accuracy: 0.7263 - val_loss: 0.8721 - val_accuracy: 0.4760\n",
      "Epoch 118/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5449 - accuracy: 0.7246 - val_loss: 0.8794 - val_accuracy: 0.4800\n",
      "Epoch 119/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5428 - accuracy: 0.7108 - val_loss: 0.8854 - val_accuracy: 0.4760\n",
      "Epoch 120/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5433 - accuracy: 0.7298 - val_loss: 0.8673 - val_accuracy: 0.4920\n",
      "Epoch 121/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5426 - accuracy: 0.7470 - val_loss: 0.8969 - val_accuracy: 0.4680\n",
      "Epoch 122/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5410 - accuracy: 0.7315 - val_loss: 0.8778 - val_accuracy: 0.4880\n",
      "Epoch 123/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5400 - accuracy: 0.7384 - val_loss: 0.8791 - val_accuracy: 0.4840\n",
      "Epoch 124/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5410 - accuracy: 0.7281 - val_loss: 0.8900 - val_accuracy: 0.4840\n",
      "Epoch 125/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5391 - accuracy: 0.7263 - val_loss: 0.8970 - val_accuracy: 0.4840\n",
      "Epoch 126/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5376 - accuracy: 0.7281 - val_loss: 0.8799 - val_accuracy: 0.5080\n",
      "Epoch 127/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5354 - accuracy: 0.7504 - val_loss: 0.8932 - val_accuracy: 0.4760\n",
      "Epoch 128/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5361 - accuracy: 0.7401 - val_loss: 0.8848 - val_accuracy: 0.4840\n",
      "Epoch 129/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5336 - accuracy: 0.7418 - val_loss: 0.9014 - val_accuracy: 0.4920\n",
      "Epoch 130/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5308 - accuracy: 0.7418 - val_loss: 0.9035 - val_accuracy: 0.4800\n",
      "Epoch 131/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5310 - accuracy: 0.7453 - val_loss: 0.8937 - val_accuracy: 0.5120\n",
      "Epoch 132/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5317 - accuracy: 0.7487 - val_loss: 0.9075 - val_accuracy: 0.4960\n",
      "Epoch 133/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5268 - accuracy: 0.7315 - val_loss: 0.8948 - val_accuracy: 0.5000\n",
      "Epoch 134/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5297 - accuracy: 0.7349 - val_loss: 0.8971 - val_accuracy: 0.5040\n",
      "Epoch 135/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5281 - accuracy: 0.7384 - val_loss: 0.8970 - val_accuracy: 0.4800\n",
      "Epoch 136/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5265 - accuracy: 0.7367 - val_loss: 0.9184 - val_accuracy: 0.4800\n",
      "Epoch 137/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5294 - accuracy: 0.7539 - val_loss: 0.8966 - val_accuracy: 0.4880\n",
      "Epoch 138/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5262 - accuracy: 0.7435 - val_loss: 0.8994 - val_accuracy: 0.4880\n",
      "Epoch 139/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5232 - accuracy: 0.7487 - val_loss: 0.9076 - val_accuracy: 0.4920\n",
      "Epoch 140/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5230 - accuracy: 0.7229 - val_loss: 0.9266 - val_accuracy: 0.4720\n",
      "Epoch 141/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5225 - accuracy: 0.7642 - val_loss: 0.9176 - val_accuracy: 0.4840\n",
      "Epoch 142/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5229 - accuracy: 0.7539 - val_loss: 0.9175 - val_accuracy: 0.4840\n",
      "Epoch 143/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5207 - accuracy: 0.7487 - val_loss: 0.9218 - val_accuracy: 0.4880\n",
      "Epoch 144/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5206 - accuracy: 0.7470 - val_loss: 0.9244 - val_accuracy: 0.4720\n",
      "Epoch 145/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5204 - accuracy: 0.7504 - val_loss: 0.9315 - val_accuracy: 0.4720\n",
      "Epoch 146/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5156 - accuracy: 0.7625 - val_loss: 0.9266 - val_accuracy: 0.4840\n",
      "Epoch 147/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5179 - accuracy: 0.7590 - val_loss: 0.9153 - val_accuracy: 0.4840\n",
      "Epoch 148/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5157 - accuracy: 0.7470 - val_loss: 0.9182 - val_accuracy: 0.4880\n",
      "Epoch 149/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5151 - accuracy: 0.7401 - val_loss: 0.9212 - val_accuracy: 0.4840\n",
      "Epoch 150/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5136 - accuracy: 0.7608 - val_loss: 0.9287 - val_accuracy: 0.4800\n",
      "Epoch 151/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5096 - accuracy: 0.7642 - val_loss: 0.9502 - val_accuracy: 0.4960\n",
      "Epoch 152/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5149 - accuracy: 0.7522 - val_loss: 0.9229 - val_accuracy: 0.4920\n",
      "Epoch 153/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5122 - accuracy: 0.7522 - val_loss: 0.9332 - val_accuracy: 0.4840\n",
      "Epoch 154/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5099 - accuracy: 0.7659 - val_loss: 0.9382 - val_accuracy: 0.4640\n",
      "Epoch 155/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5063 - accuracy: 0.7573 - val_loss: 0.9935 - val_accuracy: 0.4720\n",
      "Epoch 156/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.9402 - val_accuracy: 0.4880\n",
      "Epoch 157/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5095 - accuracy: 0.7556 - val_loss: 0.9423 - val_accuracy: 0.4760\n",
      "Epoch 158/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5049 - accuracy: 0.7642 - val_loss: 0.9365 - val_accuracy: 0.4720\n",
      "Epoch 159/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5022 - accuracy: 0.7608 - val_loss: 0.9586 - val_accuracy: 0.4880\n",
      "Epoch 160/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5039 - accuracy: 0.7625 - val_loss: 0.9527 - val_accuracy: 0.4640\n",
      "Epoch 161/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5026 - accuracy: 0.7711 - val_loss: 0.9416 - val_accuracy: 0.4800\n",
      "Epoch 162/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5013 - accuracy: 0.7694 - val_loss: 0.9443 - val_accuracy: 0.4920\n",
      "Epoch 163/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5022 - accuracy: 0.7573 - val_loss: 0.9570 - val_accuracy: 0.4920\n",
      "Epoch 164/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4978 - accuracy: 0.7659 - val_loss: 0.9453 - val_accuracy: 0.4840\n",
      "Epoch 165/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4998 - accuracy: 0.7556 - val_loss: 0.9941 - val_accuracy: 0.4960\n",
      "Epoch 166/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.5033 - accuracy: 0.7573 - val_loss: 0.9629 - val_accuracy: 0.4840\n",
      "Epoch 167/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4984 - accuracy: 0.7659 - val_loss: 0.9536 - val_accuracy: 0.4840\n",
      "Epoch 168/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4991 - accuracy: 0.7711 - val_loss: 0.9999 - val_accuracy: 0.4960\n",
      "Epoch 169/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4925 - accuracy: 0.7590 - val_loss: 0.9647 - val_accuracy: 0.4680\n",
      "Epoch 170/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4906 - accuracy: 0.7676 - val_loss: 0.9632 - val_accuracy: 0.4600\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4967 - accuracy: 0.7625 - val_loss: 0.9785 - val_accuracy: 0.4680\n",
      "Epoch 172/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4945 - accuracy: 0.7659 - val_loss: 0.9688 - val_accuracy: 0.4800\n",
      "Epoch 173/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4905 - accuracy: 0.7642 - val_loss: 0.9970 - val_accuracy: 0.5000\n",
      "Epoch 174/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4934 - accuracy: 0.7780 - val_loss: 0.9740 - val_accuracy: 0.4640\n",
      "Epoch 175/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4926 - accuracy: 0.7711 - val_loss: 0.9641 - val_accuracy: 0.4960\n",
      "Epoch 176/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4901 - accuracy: 0.7780 - val_loss: 0.9661 - val_accuracy: 0.4880\n",
      "Epoch 177/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4910 - accuracy: 0.7728 - val_loss: 0.9682 - val_accuracy: 0.4840\n",
      "Epoch 178/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4854 - accuracy: 0.7866 - val_loss: 1.0201 - val_accuracy: 0.4920\n",
      "Epoch 179/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4838 - accuracy: 0.7676 - val_loss: 0.9812 - val_accuracy: 0.4720\n",
      "Epoch 180/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4842 - accuracy: 0.7814 - val_loss: 0.9718 - val_accuracy: 0.4840\n",
      "Epoch 181/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4868 - accuracy: 0.7676 - val_loss: 1.0011 - val_accuracy: 0.5000\n",
      "Epoch 182/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4864 - accuracy: 0.7797 - val_loss: 0.9805 - val_accuracy: 0.4840\n",
      "Epoch 183/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4833 - accuracy: 0.7849 - val_loss: 0.9878 - val_accuracy: 0.4640\n",
      "Epoch 184/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4837 - accuracy: 0.7745 - val_loss: 0.9916 - val_accuracy: 0.4920\n",
      "Epoch 185/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4806 - accuracy: 0.7711 - val_loss: 0.9922 - val_accuracy: 0.4880\n",
      "Epoch 186/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4757 - accuracy: 0.7780 - val_loss: 1.0098 - val_accuracy: 0.4960\n",
      "Epoch 187/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4793 - accuracy: 0.7849 - val_loss: 0.9820 - val_accuracy: 0.4800\n",
      "Epoch 188/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4740 - accuracy: 0.7917 - val_loss: 1.0288 - val_accuracy: 0.4880\n",
      "Epoch 189/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4783 - accuracy: 0.7728 - val_loss: 1.0082 - val_accuracy: 0.5000\n",
      "Epoch 190/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4793 - accuracy: 0.7849 - val_loss: 0.9900 - val_accuracy: 0.4920\n",
      "Epoch 191/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4749 - accuracy: 0.7849 - val_loss: 1.0066 - val_accuracy: 0.4760\n",
      "Epoch 192/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4740 - accuracy: 0.7797 - val_loss: 1.0341 - val_accuracy: 0.4960\n",
      "Epoch 193/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4775 - accuracy: 0.7780 - val_loss: 0.9980 - val_accuracy: 0.4760\n",
      "Epoch 194/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4721 - accuracy: 0.7728 - val_loss: 1.0091 - val_accuracy: 0.4880\n",
      "Epoch 195/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4720 - accuracy: 0.7883 - val_loss: 1.0108 - val_accuracy: 0.4720\n",
      "Epoch 196/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4671 - accuracy: 0.7883 - val_loss: 1.0265 - val_accuracy: 0.4920\n",
      "Epoch 197/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4673 - accuracy: 0.8003 - val_loss: 1.0458 - val_accuracy: 0.4840\n",
      "Epoch 198/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4717 - accuracy: 0.7900 - val_loss: 1.0159 - val_accuracy: 0.5000\n",
      "Epoch 199/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4627 - accuracy: 0.7917 - val_loss: 1.0358 - val_accuracy: 0.5040\n",
      "Epoch 200/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4693 - accuracy: 0.7935 - val_loss: 1.0264 - val_accuracy: 0.4880\n",
      "Epoch 201/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4669 - accuracy: 0.7797 - val_loss: 1.0231 - val_accuracy: 0.4760\n",
      "Epoch 202/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4647 - accuracy: 0.7814 - val_loss: 1.0296 - val_accuracy: 0.4840\n",
      "Epoch 203/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4655 - accuracy: 0.7883 - val_loss: 1.0259 - val_accuracy: 0.4800\n",
      "Epoch 204/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4591 - accuracy: 0.7762 - val_loss: 1.0212 - val_accuracy: 0.4880\n",
      "Epoch 205/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4599 - accuracy: 0.7969 - val_loss: 1.0285 - val_accuracy: 0.4760\n",
      "Epoch 206/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4621 - accuracy: 0.7917 - val_loss: 1.0247 - val_accuracy: 0.4760\n",
      "Epoch 207/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4590 - accuracy: 0.7883 - val_loss: 1.0315 - val_accuracy: 0.4720\n",
      "Epoch 208/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4609 - accuracy: 0.7814 - val_loss: 1.0294 - val_accuracy: 0.4800\n",
      "Epoch 209/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4584 - accuracy: 0.7849 - val_loss: 1.0476 - val_accuracy: 0.5040\n",
      "Epoch 210/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4574 - accuracy: 0.7952 - val_loss: 1.0329 - val_accuracy: 0.4800\n",
      "Epoch 211/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4577 - accuracy: 0.7866 - val_loss: 1.0259 - val_accuracy: 0.4800\n",
      "Epoch 212/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4547 - accuracy: 0.7831 - val_loss: 1.0448 - val_accuracy: 0.5000\n",
      "Epoch 213/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4561 - accuracy: 0.7935 - val_loss: 1.0364 - val_accuracy: 0.4800\n",
      "Epoch 214/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4530 - accuracy: 0.7831 - val_loss: 1.0473 - val_accuracy: 0.5000\n",
      "Epoch 215/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4561 - accuracy: 0.7935 - val_loss: 1.0290 - val_accuracy: 0.4720\n",
      "Epoch 216/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4511 - accuracy: 0.7814 - val_loss: 1.0341 - val_accuracy: 0.4840\n",
      "Epoch 217/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4507 - accuracy: 0.7866 - val_loss: 1.0463 - val_accuracy: 0.4800\n",
      "Epoch 218/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4507 - accuracy: 0.8021 - val_loss: 1.0586 - val_accuracy: 0.4840\n",
      "Epoch 219/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4494 - accuracy: 0.7883 - val_loss: 1.0430 - val_accuracy: 0.4880\n",
      "Epoch 220/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4485 - accuracy: 0.8021 - val_loss: 1.0800 - val_accuracy: 0.5000\n",
      "Epoch 221/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4493 - accuracy: 0.7900 - val_loss: 1.0886 - val_accuracy: 0.4960\n",
      "Epoch 222/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4489 - accuracy: 0.7952 - val_loss: 1.0566 - val_accuracy: 0.4760\n",
      "Epoch 223/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4462 - accuracy: 0.8038 - val_loss: 1.0463 - val_accuracy: 0.4720\n",
      "Epoch 224/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4469 - accuracy: 0.7986 - val_loss: 1.0804 - val_accuracy: 0.4880\n",
      "Epoch 225/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4429 - accuracy: 0.8107 - val_loss: 1.0607 - val_accuracy: 0.4840\n",
      "Epoch 226/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4427 - accuracy: 0.8038 - val_loss: 1.0766 - val_accuracy: 0.4920\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4428 - accuracy: 0.8021 - val_loss: 1.0565 - val_accuracy: 0.4760\n",
      "Epoch 228/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4401 - accuracy: 0.8038 - val_loss: 1.0564 - val_accuracy: 0.4920\n",
      "Epoch 229/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4362 - accuracy: 0.8158 - val_loss: 1.0965 - val_accuracy: 0.4600\n",
      "Epoch 230/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4396 - accuracy: 0.7952 - val_loss: 1.0614 - val_accuracy: 0.4720\n",
      "Epoch 231/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4367 - accuracy: 0.7952 - val_loss: 1.0704 - val_accuracy: 0.4840\n",
      "Epoch 232/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4369 - accuracy: 0.8107 - val_loss: 1.0630 - val_accuracy: 0.4760\n",
      "Epoch 233/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4394 - accuracy: 0.7952 - val_loss: 1.0926 - val_accuracy: 0.5040\n",
      "Epoch 234/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4321 - accuracy: 0.8072 - val_loss: 1.0677 - val_accuracy: 0.4960\n",
      "Epoch 235/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4336 - accuracy: 0.8210 - val_loss: 1.0678 - val_accuracy: 0.5000\n",
      "Epoch 236/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4321 - accuracy: 0.8038 - val_loss: 1.0773 - val_accuracy: 0.4760\n",
      "Epoch 237/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 1.0785 - val_accuracy: 0.4760\n",
      "Epoch 238/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4340 - accuracy: 0.8210 - val_loss: 1.0962 - val_accuracy: 0.4960\n",
      "Epoch 239/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 1.1065 - val_accuracy: 0.5000\n",
      "Epoch 240/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 1.0866 - val_accuracy: 0.4880\n",
      "Epoch 241/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4339 - accuracy: 0.7952 - val_loss: 1.0797 - val_accuracy: 0.4880\n",
      "Epoch 242/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4293 - accuracy: 0.8176 - val_loss: 1.0890 - val_accuracy: 0.4840\n",
      "Epoch 243/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4263 - accuracy: 0.8158 - val_loss: 1.1001 - val_accuracy: 0.4920\n",
      "Epoch 244/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8176 - val_loss: 1.0943 - val_accuracy: 0.4880\n",
      "Epoch 245/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4253 - accuracy: 0.8124 - val_loss: 1.1177 - val_accuracy: 0.4840\n",
      "Epoch 246/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4290 - accuracy: 0.8244 - val_loss: 1.0942 - val_accuracy: 0.4800\n",
      "Epoch 247/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 1.1042 - val_accuracy: 0.4960\n",
      "Epoch 248/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4223 - accuracy: 0.8107 - val_loss: 1.0935 - val_accuracy: 0.4800\n",
      "Epoch 249/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 1.0955 - val_accuracy: 0.4880\n",
      "Epoch 250/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4246 - accuracy: 0.8072 - val_loss: 1.0957 - val_accuracy: 0.4760\n",
      "Epoch 251/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4195 - accuracy: 0.8158 - val_loss: 1.1110 - val_accuracy: 0.4880\n",
      "Epoch 252/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4178 - accuracy: 0.8244 - val_loss: 1.1260 - val_accuracy: 0.5040\n",
      "Epoch 253/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4230 - accuracy: 0.8141 - val_loss: 1.0978 - val_accuracy: 0.4720\n",
      "Epoch 254/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4191 - accuracy: 0.8038 - val_loss: 1.1184 - val_accuracy: 0.5040\n",
      "Epoch 255/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4176 - accuracy: 0.8141 - val_loss: 1.1117 - val_accuracy: 0.4880\n",
      "Epoch 256/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 1.1232 - val_accuracy: 0.4800\n",
      "Epoch 257/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4163 - accuracy: 0.8176 - val_loss: 1.1035 - val_accuracy: 0.4720\n",
      "Epoch 258/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 1.1281 - val_accuracy: 0.4760\n",
      "Epoch 259/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4147 - accuracy: 0.8244 - val_loss: 1.1239 - val_accuracy: 0.4920\n",
      "Epoch 260/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4125 - accuracy: 0.8193 - val_loss: 1.1281 - val_accuracy: 0.4800\n",
      "Epoch 261/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4124 - accuracy: 0.8176 - val_loss: 1.1248 - val_accuracy: 0.4960\n",
      "Epoch 262/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4133 - accuracy: 0.8176 - val_loss: 1.1192 - val_accuracy: 0.4920\n",
      "Epoch 263/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4094 - accuracy: 0.8193 - val_loss: 1.1193 - val_accuracy: 0.4840\n",
      "Epoch 264/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4099 - accuracy: 0.8262 - val_loss: 1.1180 - val_accuracy: 0.4880\n",
      "Epoch 265/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4087 - accuracy: 0.8124 - val_loss: 1.1212 - val_accuracy: 0.4960\n",
      "Epoch 266/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4073 - accuracy: 0.8296 - val_loss: 1.1324 - val_accuracy: 0.4720\n",
      "Epoch 267/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4078 - accuracy: 0.8193 - val_loss: 1.1374 - val_accuracy: 0.4880\n",
      "Epoch 268/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4061 - accuracy: 0.8365 - val_loss: 1.1427 - val_accuracy: 0.4680\n",
      "Epoch 269/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4029 - accuracy: 0.8210 - val_loss: 1.1288 - val_accuracy: 0.4840\n",
      "Epoch 270/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4019 - accuracy: 0.8296 - val_loss: 1.1645 - val_accuracy: 0.4800\n",
      "Epoch 271/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4029 - accuracy: 0.8124 - val_loss: 1.1365 - val_accuracy: 0.4840\n",
      "Epoch 272/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4052 - accuracy: 0.8296 - val_loss: 1.1422 - val_accuracy: 0.4680\n",
      "Epoch 273/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4010 - accuracy: 0.8176 - val_loss: 1.1351 - val_accuracy: 0.4800\n",
      "Epoch 274/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3976 - accuracy: 0.8193 - val_loss: 1.1387 - val_accuracy: 0.4880\n",
      "Epoch 275/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.4028 - accuracy: 0.8193 - val_loss: 1.1343 - val_accuracy: 0.5000\n",
      "Epoch 276/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3957 - accuracy: 0.8296 - val_loss: 1.1433 - val_accuracy: 0.4880\n",
      "Epoch 277/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3982 - accuracy: 0.8313 - val_loss: 1.1611 - val_accuracy: 0.4720\n",
      "Epoch 278/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3989 - accuracy: 0.8313 - val_loss: 1.1517 - val_accuracy: 0.4960\n",
      "Epoch 279/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3969 - accuracy: 0.8279 - val_loss: 1.1487 - val_accuracy: 0.4960\n",
      "Epoch 280/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3961 - accuracy: 0.8382 - val_loss: 1.1442 - val_accuracy: 0.4920\n",
      "Epoch 281/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3907 - accuracy: 0.8365 - val_loss: 1.1473 - val_accuracy: 0.5040\n",
      "Epoch 282/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3926 - accuracy: 0.8158 - val_loss: 1.1431 - val_accuracy: 0.4960\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3947 - accuracy: 0.8313 - val_loss: 1.1549 - val_accuracy: 0.4760\n",
      "Epoch 284/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3954 - accuracy: 0.8158 - val_loss: 1.1585 - val_accuracy: 0.5000\n",
      "Epoch 285/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3946 - accuracy: 0.8382 - val_loss: 1.1485 - val_accuracy: 0.4760\n",
      "Epoch 286/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3903 - accuracy: 0.8382 - val_loss: 1.1620 - val_accuracy: 0.4960\n",
      "Epoch 287/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3909 - accuracy: 0.8296 - val_loss: 1.1622 - val_accuracy: 0.4760\n",
      "Epoch 288/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3907 - accuracy: 0.8313 - val_loss: 1.1530 - val_accuracy: 0.5000\n",
      "Epoch 289/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3894 - accuracy: 0.8262 - val_loss: 1.1712 - val_accuracy: 0.4880\n",
      "Epoch 290/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3851 - accuracy: 0.8296 - val_loss: 1.1949 - val_accuracy: 0.4760\n",
      "Epoch 291/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3882 - accuracy: 0.8382 - val_loss: 1.1684 - val_accuracy: 0.4920\n",
      "Epoch 292/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3837 - accuracy: 0.8348 - val_loss: 1.2457 - val_accuracy: 0.4520\n",
      "Epoch 293/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3824 - accuracy: 0.8313 - val_loss: 1.1658 - val_accuracy: 0.4840\n",
      "Epoch 294/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3851 - accuracy: 0.8468 - val_loss: 1.1724 - val_accuracy: 0.4840\n",
      "Epoch 295/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3821 - accuracy: 0.8348 - val_loss: 1.2267 - val_accuracy: 0.4840\n",
      "Epoch 296/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3830 - accuracy: 0.8313 - val_loss: 1.1697 - val_accuracy: 0.4920\n",
      "Epoch 297/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3784 - accuracy: 0.8296 - val_loss: 1.1801 - val_accuracy: 0.5040\n",
      "Epoch 298/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3837 - accuracy: 0.8417 - val_loss: 1.1857 - val_accuracy: 0.4960\n",
      "Epoch 299/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3823 - accuracy: 0.8313 - val_loss: 1.1708 - val_accuracy: 0.4960\n",
      "Epoch 300/300\n",
      "581/581 [==============================] - 2s 4ms/step - loss: 0.3811 - accuracy: 0.8330 - val_loss: 1.1961 - val_accuracy: 0.4720\n",
      "CPU times: user 9min 59s, sys: 5min 54s, total: 15min 53s\n",
      "Wall time: 10min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_split=0.3, epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c016a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 10:21:56.283815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "train_preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c332151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64a18c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_list(x) :\n",
    "    temp_df = pd.DataFrame(x)\n",
    "    temp_df['res'] = temp_df[0] < temp_df[1]\n",
    "    return temp_df['res'].apply(lambda x: int(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d25986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54       175\n",
      "           1       0.54      0.50      0.52       182\n",
      "\n",
      "    accuracy                           0.53       357\n",
      "   macro avg       0.53      0.53      0.53       357\n",
      "weighted avg       0.53      0.53      0.53       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(give_list(test_preds), give_list(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94880e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       405\n",
      "           1       0.76      0.72      0.74       426\n",
      "\n",
      "    accuracy                           0.74       831\n",
      "   macro avg       0.74      0.74      0.74       831\n",
      "weighted avg       0.74      0.74      0.74       831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(give_list(train_preds), give_list(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd878e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701da90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7ca2601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = timedelta(days=1)\n",
    "\n",
    "X_v = []\n",
    "y_v = []\n",
    "v_dates = []\n",
    "\n",
    "temp = None\n",
    "\n",
    "for idx in range(len(holiday_list)-300, len(holiday_list)) :\n",
    "    \n",
    "    #휴일 시작일\n",
    "    holiday_start = holiday_list[idx][0]\n",
    "    \n",
    "    #휴일 종료일\n",
    "    holiday_end = holiday_list[idx][1]\n",
    "    \n",
    "    # 타겟 날짜(휴일 다음날의 날짜)\n",
    "    target_day = holiday_end + one_day\n",
    "    \n",
    "    # 휴일기간 및 D+1일 지수 변동 데이터\n",
    "    n_holiday = final_df.loc[holiday_start - one_day : holiday_end]\n",
    "    \n",
    "#     if len(n_holiday) > 3:\n",
    "#         temp = n_holiday\n",
    "#         break\n",
    "    \n",
    "    # 휴일 기간 동안 지수들의 누적 변동률\n",
    "    n_holiday_change = (n_holiday + 1).cumprod() - 1\n",
    "\n",
    "    # KOSPI, KOSDAQ을 제외한 지수들의 누적수익률 데이터\n",
    "    X_data = n_holiday_change.loc[holiday_end].apply(lambda x : round(x, 4))\n",
    "\n",
    "    # D+1일 KOSPI의 실제 수익률 y\n",
    "    y_data = y_df.loc[target_day].apply(lambda x : round(x, 4))['y']\n",
    "    v_dates.append(target_day)\n",
    "    X_v.append(X_data.values)\n",
    "    y_v.append(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1678e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = np.array(X_v)\n",
    "y_v = np.array(y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a490a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b39b00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d2887a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['res'] = temp_df[0] < temp_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2a51e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['res'] = temp_df.res.apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0725ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {\n",
    "    \"date\" : v_dates,\n",
    "    \"preds\" : temp_df.res.values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "99760ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2975c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c14743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.merge(val_df, kospi, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e479ae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-25</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.32</td>\n",
       "      <td>2014.74</td>\n",
       "      <td>2020.69</td>\n",
       "      <td>2006.63</td>\n",
       "      <td>350230000.0</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-01</th>\n",
       "      <td>0</td>\n",
       "      <td>2029.61</td>\n",
       "      <td>2024.71</td>\n",
       "      <td>2031.58</td>\n",
       "      <td>2024.57</td>\n",
       "      <td>369590000.0</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-08</th>\n",
       "      <td>0</td>\n",
       "      <td>2031.12</td>\n",
       "      <td>2025.55</td>\n",
       "      <td>2031.14</td>\n",
       "      <td>2018.81</td>\n",
       "      <td>270480000.0</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-16</th>\n",
       "      <td>0</td>\n",
       "      <td>2047.76</td>\n",
       "      <td>2056.00</td>\n",
       "      <td>2063.09</td>\n",
       "      <td>2047.73</td>\n",
       "      <td>374870000.0</td>\n",
       "      <td>-0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-22</th>\n",
       "      <td>1</td>\n",
       "      <td>2042.16</td>\n",
       "      <td>2054.37</td>\n",
       "      <td>2054.71</td>\n",
       "      <td>2040.51</td>\n",
       "      <td>343500000.0</td>\n",
       "      <td>-0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>0</td>\n",
       "      <td>2962.17</td>\n",
       "      <td>2998.17</td>\n",
       "      <td>2998.17</td>\n",
       "      <td>2940.59</td>\n",
       "      <td>840560000.0</td>\n",
       "      <td>-0.0189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-12</th>\n",
       "      <td>0</td>\n",
       "      <td>2916.38</td>\n",
       "      <td>2950.22</td>\n",
       "      <td>2950.94</td>\n",
       "      <td>2901.51</td>\n",
       "      <td>660180000.0</td>\n",
       "      <td>-0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-18</th>\n",
       "      <td>0</td>\n",
       "      <td>3006.68</td>\n",
       "      <td>3017.48</td>\n",
       "      <td>3021.17</td>\n",
       "      <td>2990.44</td>\n",
       "      <td>926370000.0</td>\n",
       "      <td>-0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>1</td>\n",
       "      <td>3020.54</td>\n",
       "      <td>3001.10</td>\n",
       "      <td>3025.27</td>\n",
       "      <td>2983.29</td>\n",
       "      <td>791800000.0</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>0</td>\n",
       "      <td>2978.94</td>\n",
       "      <td>2984.18</td>\n",
       "      <td>2991.81</td>\n",
       "      <td>2976.87</td>\n",
       "      <td>475380000.0</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            preds    Close     Open     High      Low       Volume  Change\n",
       "2016-07-25      1  2012.32  2014.74  2020.69  2006.63  350230000.0  0.0010\n",
       "2016-08-01      0  2029.61  2024.71  2031.58  2024.57  369590000.0  0.0067\n",
       "2016-08-08      0  2031.12  2025.55  2031.14  2018.81  270480000.0  0.0065\n",
       "2016-08-16      0  2047.76  2056.00  2063.09  2047.73  374870000.0 -0.0013\n",
       "2016-08-22      1  2042.16  2054.37  2054.71  2040.51  343500000.0 -0.0068\n",
       "...           ...      ...      ...      ...      ...          ...     ...\n",
       "2021-10-05      0  2962.17  2998.17  2998.17  2940.59  840560000.0 -0.0189\n",
       "2021-10-12      0  2916.38  2950.22  2950.94  2901.51  660180000.0 -0.0135\n",
       "2021-10-18      0  3006.68  3017.48  3021.17  2990.44  926370000.0 -0.0028\n",
       "2021-10-25      1  3020.54  3001.10  3025.27  2983.29  791800000.0  0.0048\n",
       "2021-11-01      0  2978.94  2984.18  2991.81  2976.87  475380000.0  0.0028\n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a95e0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['gap'] = (val_df.Close - val_df.Open) / val_df.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fdc4e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['cum'] = val_df['preds'] * val_df['gap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4942f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(val_df.cum + 1).cumprod().plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1fb71e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-07-25    0.998799\n",
       "2016-08-01    0.998799\n",
       "2016-08-08    0.998799\n",
       "2016-08-16    0.998799\n",
       "2016-08-22    0.992863\n",
       "                ...   \n",
       "2021-10-05    1.265499\n",
       "2021-10-12    1.265499\n",
       "2021-10-18    1.265499\n",
       "2021-10-25    1.273697\n",
       "2021-11-01    1.273697\n",
       "Name: cum, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_df.cum + 1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe5879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
